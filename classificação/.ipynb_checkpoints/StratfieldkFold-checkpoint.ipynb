{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('../data/bill_authentication.csv')\n",
    "base.head()\n",
    "\n",
    "features_ = base.drop(['Class'], axis=1).values\n",
    "class_ = base['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features_ = scaler.fit_transform(features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index train:  [   0    1    2 ... 1368 1370 1371] index test:  [   3   61   65   85   87  112  121  123  131  137  140  144  150  157\n",
      "  160  166  180  187  194  198  199  211  216  228  229  232  239  248\n",
      "  249  264  268  303  304  312  352  353  359  361  370  378  380  386\n",
      "  387  393  402  458  464  478  499  521  522  540  552  554  562  565\n",
      "  573  578  596  600  608  631  637  665  667  675  687  706  710  712\n",
      "  713  719  725  729  730  733  740  750  805  813  815  818  823  833\n",
      "  835  852  857  868  886  888  891  898  904  916  929  947  950  960\n",
      "  965  976  986 1005 1018 1029 1043 1073 1087 1088 1090 1103 1112 1113\n",
      " 1115 1117 1144 1174 1177 1198 1201 1216 1223 1225 1237 1258 1266 1268\n",
      " 1275 1277 1278 1295 1299 1304 1305 1309 1321 1326 1347 1369]\n",
      "index train:  [   0    2    3 ... 1369 1370 1371] index test:  [   1    6   19   30   31   42   48   50   57   58   64   69   70   72\n",
      "   80   81   86   97  103  107  119  143  148  178  186  188  193  197\n",
      "  201  209  243  247  263  288  290  293  301  316  317  318  323  327\n",
      "  335  343  349  357  400  407  411  421  423  427  429  448  456  472\n",
      "  490  493  498  516  537  563  568  577  585  587  594  595  610  626\n",
      "  633  646  648  654  669  677  685  686  689  693  707  708  709  717\n",
      "  718  727  737  744  747  751  760  774  777  781  786  811  837  840\n",
      "  841  845  853  859  880  899  921  927  932  949  993  995 1035 1041\n",
      " 1048 1056 1079 1091 1116 1119 1125 1153 1179 1182 1183 1213 1243 1260\n",
      " 1281 1283 1285 1288 1294 1300 1301 1319 1334 1337 1350 1354]\n",
      "index train:  [   0    1    2 ... 1369 1370 1371] index test:  [  16   27   45   46   73   78   83   91   95  109  115  116  122  146\n",
      "  147  152  154  164  168  173  175  190  202  210  214  227  235  238\n",
      "  262  266  296  321  324  328  330  334  339  347  360  362  374  381\n",
      "  416  425  439  442  447  450  471  475  477  485  492  526  529  539\n",
      "  548  549  581  586  593  597  606  612  613  614  670  678  679  688\n",
      "  723  745  763  780  782  784  785  791  804  809  831  849  873  881\n",
      "  883  890  893  910  913  928  942  944  946  951  959  973  982  984\n",
      "  999 1000 1002 1009 1015 1061 1063 1067 1081 1097 1100 1126 1127 1147\n",
      " 1156 1159 1160 1162 1189 1199 1214 1219 1228 1230 1244 1245 1255 1257\n",
      " 1259 1264 1269 1272 1306 1322 1331 1335 1339 1346 1352]\n",
      "index train:  [   0    1    2 ... 1369 1370 1371] index test:  [   4    7   22   28   51   75   92   93   99  108  126  128  130  132\n",
      "  139  155  162  169  170  189  203  204  205  206  221  224  246  255\n",
      "  269  270  287  311  314  350  355  376  377  389  391  428  431  440\n",
      "  468  469  482  487  488  502  509  514  515  550  570  583  588  592\n",
      "  602  603  615  616  620  623  635  636  656  660  692  702  703  711\n",
      "  746  749  761  783  796  800  821  866  869  876  877  884  885  892\n",
      "  896  909  914  923  930  940  954  971  975  989 1006 1038 1040 1054\n",
      " 1055 1059 1064 1069 1075 1077 1078 1083 1109 1134 1139 1141 1142 1145\n",
      " 1157 1166 1185 1204 1206 1209 1210 1211 1221 1222 1233 1234 1235 1250\n",
      " 1253 1280 1297 1303 1308 1312 1315 1357 1358 1361 1366]\n",
      "index train:  [   1    2    3 ... 1368 1369 1371] index test:  [   0    5   10   34   39   41   67   68   89  101  102  111  118  124\n",
      "  134  136  138  145  177  179  192  195  252  265  297  300  336  354\n",
      "  358  385  410  415  420  437  445  449  452  454  457  460  465  505\n",
      "  506  517  523  527  528  542  546  557  558  560  566  574  590  611\n",
      "  617  618  638  649  663  671  674  697  720  726  743  752  756  758\n",
      "  759  768  769  771  778  792  807  816  825  851  894  897  905  915\n",
      "  919  931  937  938  941  948  956  963  969  972  979  997 1008 1013\n",
      " 1014 1020 1022 1027 1032 1036 1042 1051 1092 1106 1120 1122 1140 1148\n",
      " 1149 1169 1178 1190 1191 1193 1200 1212 1227 1229 1238 1249 1254 1256\n",
      " 1274 1284 1286 1290 1316 1318 1324 1330 1341 1364 1370]\n",
      "index train:  [   0    1    2 ... 1369 1370 1371] index test:  [  14   37   55   56   59   74  105  106  127  159  163  215  233  236\n",
      "  237  251  261  279  291  294  319  322  333  338  351  356  371  390\n",
      "  392  399  401  406  409  412  422  443  446  459  461  462  466  479\n",
      "  518  533  534  543  555  589  591  609  619  624  628  629  632  639\n",
      "  644  650  658  664  668  673  681  682  698  715  721  736  741  742\n",
      "  753  755  787  794  799  803  806  819  820  842  843  847  854  855\n",
      "  861  863  871  879  895  920  933  934  935  953  955  958  962  977\n",
      "  985  990  991 1012 1034 1068 1072 1080 1082 1089 1094 1101 1105 1107\n",
      " 1108 1110 1111 1121 1128 1130 1132 1138 1146 1163 1164 1187 1188 1203\n",
      " 1205 1208 1215 1239 1246 1287 1296 1336 1338 1342 1363]\n",
      "index train:  [   0    1    2 ... 1369 1370 1371] index test:  [   8   20   21   38   40   43   49   53   66   79  114  129  135  142\n",
      "  151  181  185  191  230  231  250  257  271  272  283  284  289  306\n",
      "  313  315  326  329  340  342  345  346  373  384  388  395  397  405\n",
      "  414  417  473  481  491  495  500  504  512  524  525  532  536  541\n",
      "  567  569  579  642  643  645  652  653  683  694  696  700  716  722\n",
      "  724  762  772  801  808  827  829  856  867  870  874  889  902  903\n",
      "  908  911  925  936  943  957  978  980  981  987 1004 1011 1028 1037\n",
      " 1039 1047 1053 1070 1076 1095 1123 1124 1131 1135 1136 1137 1151 1152\n",
      " 1167 1170 1173 1192 1207 1218 1220 1232 1240 1248 1251 1263 1279 1292\n",
      " 1302 1323 1327 1329 1333 1344 1345 1348 1355 1356 1362]\n",
      "index train:  [   0    1    2 ... 1368 1369 1370] index test:  [   9   15   18   23   24   25   29   33   47   54   71   82   84   88\n",
      "   90   96   98  104  153  156  158  161  167  171  174  208  218  219\n",
      "  222  225  240  241  244  253  254  260  275  276  280  286  298  307\n",
      "  310  331  332  364  365  366  382  404  419  424  430  432  433  451\n",
      "  453  467  486  496  501  510  530  531  535  556  571  572  575  584\n",
      "  599  604  630  640  651  661  666  676  680  701  705  714  735  739\n",
      "  765  766  770  773  779  790  810  812  814  822  824  832  838  846\n",
      "  850  878  882  901  918  922  988  992  998 1007 1031 1049 1052 1060\n",
      " 1065 1071 1085 1102 1104 1129 1133 1150 1158 1168 1171 1175 1186 1196\n",
      " 1224 1226 1242 1265 1271 1307 1314 1317 1328 1343 1371]\n",
      "index train:  [   0    1    2 ... 1369 1370 1371] index test:  [  11   12   13   17   32   63   77   94  110  125  149  172  196  207\n",
      "  213  217  220  223  226  234  245  259  273  278  281  282  292  299\n",
      "  302  305  320  325  341  344  348  367  369  372  375  394  396  403\n",
      "  418  426  434  435  436  438  455  463  470  474  494  513  538  547\n",
      "  551  553  559  564  576  580  582  598  601  607  621  627  634  655\n",
      "  657  672  691  695  699  732  734  748  757  764  767  775  793  797\n",
      "  798  802  817  826  839  844  865  900  907  924  926  945  961  964\n",
      "  966  967  983  994 1023 1030 1045 1058 1062 1066 1074 1084 1093 1096\n",
      " 1098 1099 1114 1118 1154 1155 1161 1181 1194 1217 1231 1241 1252 1261\n",
      " 1267 1276 1289 1298 1325 1349 1359 1360 1365 1367 1368]\n",
      "index train:  [   0    1    3 ... 1369 1370 1371] index test:  [   2   26   35   36   44   52   60   62   76  100  113  117  120  133\n",
      "  141  165  176  182  183  184  200  212  242  256  258  267  274  277\n",
      "  285  295  308  309  337  363  368  379  383  398  408  413  441  444\n",
      "  476  480  483  484  489  497  503  507  508  511  519  520  544  545\n",
      "  561  605  622  625  641  647  659  662  684  690  704  728  731  738\n",
      "  754  776  788  789  795  828  830  834  836  848  858  860  862  864\n",
      "  872  875  887  906  912  917  939  952  968  970  974  996 1001 1003\n",
      " 1010 1016 1017 1019 1021 1024 1025 1026 1033 1044 1046 1050 1057 1086\n",
      " 1143 1165 1172 1176 1180 1184 1195 1197 1202 1236 1247 1262 1270 1273\n",
      " 1282 1291 1293 1310 1311 1313 1320 1332 1340 1351 1353]\n",
      "Results mean:  0.8396329207658944\n",
      "Results std:  0.016115708768375734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import numpy as np\n",
    "a = np.zeros(5)\n",
    "features_.shape\n",
    "features_.shape[0]\n",
    "b = np.zeros(shape=(features_.shape[0], 1))\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 3)\n",
    "results = []\n",
    "matrix = []\n",
    "for indice_train, indice_test in kfold.split(features_,\n",
    "                                                    np.zeros(shape=(features_.shape[0], 1))):\n",
    "    print('index train: ', indice_train, 'index test: ', indice_test)\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(features_[indice_train], class_[indice_train]) \n",
    "    pred = classifier.predict(features_[indice_test])\n",
    "    precision = accuracy_score(class_[indice_test], pred)\n",
    "    matrix.append(confusion_matrix(classe[indice_test], pred))\n",
    "    results.append(precision)\n",
    "\n",
    "matrix_final = np.mean(matrix, axis = 0)\n",
    "results = np.asarray(results)\n",
    "print(\"Results mean: \",results.mean())\n",
    "print(\"Results std: \",results.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
